# Deconstructions_CP2 (Total 6)
by Sarah Zaheer and Chloe Kim


# Deconstructions by Sarah Zaheer (2)

## Pavegen Power the world with footsteps: https://www.youtube.com/watch?v=VD15-2Uriyc
### Data
1) Footsteps of people stepping on the electric grid floor.

### Rendering
1) Motion sensor. 
2) Grid like floor to capture kinetic energy.
3) Electricity on led figment. 
4) Rewards on Mobile device for every step.

### Simulation
2) None.

### Events / User Input
1) None but the user's movement is captured and converted.


## The Treachery of Sanctuary: https://www.youtube.com/watch?v=I5__9hq-yas

### Data
1) Posture/movement tracking motor.
2) Image coming in from the camera.
3) 3 panels that reflect the altered silhouette of people in front of them.


### Rendering
1) Application of images/animation on body captured. 
2) Image data in panel 1 is converted into the body disintegrating into birds.
3) Image data in panel 2 is converted into the body getting picked apart by birds.
4) Image data in panel 2 is converted into the body sprouting giant wings.

### Simulation
1) None.

### Events / User Input
1) None but the user's body is captured and reflected.

# Deconstructions by Chloe kim (2)

## Pavegen Power the world with footsteps: https://www.youtube.com/watch?v=VD15-2Uriyc
### Data
1) Generates energy for people’s footsteps.
2) The energy for people’s footsteps produce kinetic energy and Pavegen Power turns it into electricity.
3) 1 footstep = 20 seconds of light.
4) Generates energy, data, and engagement.

### Rendering
1) Floor panels (grid-like) capture kinetic energy and the system in the panels turn the kinetic energy to electricity.
2) Panels are lightly pressed down (detects motions).

### Simulation:
1) None. 

### Events/User Input:
1) Mobile Devices - App to track location and find the identity of the people.
2) Walk (More physical transportation on ground, more electricity).


## The Treachery of Sanctuary: https://www.youtube.com/watch?v=I5__9hq-yas

### Data
1) 3 panels (3 stages), triptych.
2) Infrared sensors - shadow of the participants.
3) Kinect controllers & Microsoft SDK for skeleton tracking - posture, gesture, movement.

### Rendering:
1) Animation applied onto the shadow (shadow formed by the use of softwares).
2) Contrast of Black and White. 
3) The sensors follow the skeleton and the movement.

### Simulation:
1) None, participants needed.

### Events/User Input:
1) Using the posture of the participants, animation (each panel has different effects) differs in positions and creates animation on where the shadow is. 

# Collaborative Deconstructions by Chloe and Sarah (2)

## Cleaning Robot:https://www.youtube.com/watch?v=MaJlVytKGWQ

### Data
1) Infrared sensors to know more about its environment, detects obstacles.
2) Motor speed.
3) Connection to the app (system incorporated in the robot).
4) 3-Stage Cleaning system: loosens, lifts, and suction.
5) Device with the physical buttons.
6) Runs for 60 minutes.

### Rendering
1) Mobility is activated by the users.
2) 3-Stage Cleaning system: loosens, lifts, and suction.
3) Scheduling on the app.
4) Button to turn on and off the device or change setting.

### Simulation 
1) Automatic recharging.

### User Input/Events
1) Scheduling on the app.
2) Button to turn on and off the device or change setting.

## Barbican's Rain Room: https://www.youtube.com/watch?v=EkvazIZx-F0

### Data
1) 2,500 litres of water, falling at 1,000 litres per minute.
2) Tracking using 3D Depth Cameras.
3) Shape forming of the body.
4) Turning on and off individual valves.
5) Water used in rotation (transfer from bottom to top).   


### Rendering
1) Tracking using 3D Depth Cameras.
2) Shape forming of the body.
3) Turning on and off individual valves.
4) Falling at 1,000 litres per minute.

### Simulation 
1) None.


### User Input/Events

1) User mobility in the constructed area.








